{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name;Age;Experience;Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Betul1;1;6;23232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Betul2;2;2;23232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Betul3;3;4;443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Betul4;4;1;54534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Betul5;5;3;222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Betul6;6;4;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>;7;3;23232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>;;12;4545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Betul9;;1;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Betul10;9;2;3232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Name;Age;Experience;Salary\n",
       "0           Betul1;1;6;23232\n",
       "1           Betul2;2;2;23232\n",
       "2             Betul3;3;4;443\n",
       "3           Betul4;4;1;54534\n",
       "4             Betul5;5;3;222\n",
       "5                Betul6;6;4;\n",
       "6                 ;7;3;23232\n",
       "7                  ;;12;4545\n",
       "8                 Betul9;;1;\n",
       "9           Betul10;9;2;3232"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds= pd.read_csv(\"Jupyter-book.csv\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark= SparkSession.builder.appName(\"Practice\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-C06POSU.mshome.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1cc4a908050>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.csv(\"Jupyter-book.csv\", sep=\";\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|Experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "| Betul1|   1|         6| 23232|\n",
      "| Betul2|   2|         2| 23232|\n",
      "| Betul3|   3|         4|   443|\n",
      "| Betul4|   4|         1| 54534|\n",
      "| Betul5|   5|         3|   222|\n",
      "| Betul6|   6|         4|  NULL|\n",
      "|   NULL|   7|         3| 23232|\n",
      "|   NULL|NULL|        12|  4545|\n",
      "| Betul9|NULL|         1|  NULL|\n",
      "|Betul10|   9|         2|  3232|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Betul1', Age=1, Experience=6, Salary=23232),\n",
       " Row(Name='Betul2', Age=2, Experience=2, Salary=23232),\n",
       " Row(Name='Betul3', Age=3, Experience=4, Salary=443)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'Experience', 'Salary']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   Name|\n",
      "+-------+\n",
      "| Betul1|\n",
      "| Betul2|\n",
      "| Betul3|\n",
      "| Betul4|\n",
      "| Betul5|\n",
      "| Betul6|\n",
      "|   NULL|\n",
      "|   NULL|\n",
      "| Betul9|\n",
      "|Betul10|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(\"Name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: int]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.select([\"Name\", \"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Name'>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark[\"Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'int'), ('Experience', 'int'), ('Salary', 'int')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------------+-----------------+----------------+\n",
      "|summary|  Name|              Age|       Experience|          Salary|\n",
      "+-------+------+-----------------+-----------------+----------------+\n",
      "|  count|     8|                8|               10|               8|\n",
      "|   mean|  NULL|            4.625|              3.8|         16584.0|\n",
      "| stddev|  NULL|2.669269563007828|3.259175083088084|18609.7154426698|\n",
      "|    min|Betul1|                1|                1|             222|\n",
      "|    max|Betul9|                9|               12|           54534|\n",
      "+-------+------+-----------------+-----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding columns to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=df_pyspark.withColumn(\"Experience after 2 years\", df_pyspark[\"Experience\"]+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+------------------------+\n",
      "|   Name| Age|Experience|Salary|Experience after 2 years|\n",
      "+-------+----+----------+------+------------------------+\n",
      "| Betul1|   1|         6| 23232|                       8|\n",
      "| Betul2|   2|         2| 23232|                       4|\n",
      "| Betul3|   3|         4|   443|                       6|\n",
      "| Betul4|   4|         1| 54534|                       3|\n",
      "| Betul5|   5|         3|   222|                       5|\n",
      "| Betul6|   6|         4|  NULL|                       6|\n",
      "|   NULL|   7|         3| 23232|                       5|\n",
      "|   NULL|NULL|        12|  4545|                      14|\n",
      "| Betul9|NULL|         1|  NULL|                       3|\n",
      "|Betul10|   9|         2|  3232|                       4|\n",
      "+-------+----+----------+------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark= df_pyspark.drop(\"Experience after 2 years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|Experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "| Betul1|   1|         6| 23232|\n",
      "| Betul2|   2|         2| 23232|\n",
      "| Betul3|   3|         4|   443|\n",
      "| Betul4|   4|         1| 54534|\n",
      "| Betul5|   5|         3|   222|\n",
      "| Betul6|   6|         4|  NULL|\n",
      "|   NULL|   7|         3| 23232|\n",
      "|   NULL|NULL|        12|  4545|\n",
      "| Betul9|NULL|         1|  NULL|\n",
      "|Betul10|   9|         2|  3232|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+------+\n",
      "|New Name| Age|Experience|Salary|\n",
      "+--------+----+----------+------+\n",
      "|  Betul1|   1|         6| 23232|\n",
      "|  Betul2|   2|         2| 23232|\n",
      "|  Betul3|   3|         4|   443|\n",
      "|  Betul4|   4|         1| 54534|\n",
      "|  Betul5|   5|         3|   222|\n",
      "|  Betul6|   6|         4|  NULL|\n",
      "|    NULL|   7|         3| 23232|\n",
      "|    NULL|NULL|        12|  4545|\n",
      "|  Betul9|NULL|         1|  NULL|\n",
      "| Betul10|   9|         2|  3232|\n",
      "+--------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumnRenamed(\"Name\", \"New Name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "| Betul1|  1|         6| 23232|\n",
      "| Betul2|  2|         2| 23232|\n",
      "| Betul3|  3|         4|   443|\n",
      "| Betul4|  4|         1| 54534|\n",
      "| Betul5|  5|         3|   222|\n",
      "|Betul10|  9|         2|  3232|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: int, Experience: int, Salary: int]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### any=how\n",
    "df_pyspark.na.drop(how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|Experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "| Betul1|   1|         6| 23232|\n",
      "| Betul2|   2|         2| 23232|\n",
      "| Betul3|   3|         4|   443|\n",
      "| Betul4|   4|         1| 54534|\n",
      "| Betul5|   5|         3|   222|\n",
      "| Betul6|   6|         4|  NULL|\n",
      "|   NULL|   7|         3| 23232|\n",
      "|   NULL|NULL|        12|  4545|\n",
      "| Betul9|NULL|         1|  NULL|\n",
      "|Betul10|   9|         2|  3232|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "| Betul1|  1|         6| 23232|\n",
      "| Betul2|  2|         2| 23232|\n",
      "| Betul3|  3|         4|   443|\n",
      "| Betul4|  4|         1| 54534|\n",
      "| Betul5|  5|         3|   222|\n",
      "| Betul6|  6|         4|  NULL|\n",
      "|   NULL|  7|         3| 23232|\n",
      "|Betul10|  9|         2|  3232|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### threshold (at least 2 values should be not null)\n",
    "df_pyspark.na.drop(thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "| Betul1|  1|         6| 23232|\n",
      "| Betul2|  2|         2| 23232|\n",
      "| Betul3|  3|         4|   443|\n",
      "| Betul4|  4|         1| 54534|\n",
      "| Betul5|  5|         3|   222|\n",
      "| Betul6|  6|         4|  NULL|\n",
      "|   NULL|  7|         3| 23232|\n",
      "|Betul10|  9|         2|  3232|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### subset (drop non values from a aspecific columns)\n",
    "df_pyspark.na.drop(how=\"any\", subset=[\"Age\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+----------+------+\n",
      "|          Name|Age|Experience|Salary|\n",
      "+--------------+---+----------+------+\n",
      "|        Betul1|  1|         6| 23232|\n",
      "|        Betul2|  2|         2| 23232|\n",
      "|        Betul3|  3|         4|   443|\n",
      "|        Betul4|  4|         1| 54534|\n",
      "|        Betul5|  5|         3|   222|\n",
      "|        Betul6|  6|         4|     0|\n",
      "|missing values|  7|         3| 23232|\n",
      "|missing values|  0|        12|  4545|\n",
      "|        Betul9|  0|         1|     0|\n",
      "|       Betul10|  9|         2|  3232|\n",
      "+--------------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Filling the missing values\n",
    "df_pyspark.na.fill({\"Name\": \"missing values\", \"Age\": 0, \"Experience\": 0, \"Salary\": 0}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "|   Name| Age|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "| Betul1|   1|         6| 23232|          1|                 6|         23232|\n",
      "| Betul2|   2|         2| 23232|          2|                 2|         23232|\n",
      "| Betul3|   3|         4|   443|          3|                 4|           443|\n",
      "| Betul4|   4|         1| 54534|          4|                 1|         54534|\n",
      "| Betul5|   5|         3|   222|          5|                 3|           222|\n",
      "| Betul6|   6|         4|  NULL|          6|                 4|         16584|\n",
      "|   NULL|   7|         3| 23232|          7|                 3|         23232|\n",
      "|   NULL|NULL|        12|  4545|          4|                12|          4545|\n",
      "| Betul9|NULL|         1|  NULL|          4|                 1|         16584|\n",
      "|Betul10|   9|         2|  3232|          9|                 2|          3232|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputCols=[\"Age\", \"Experience\", \"Salary\"]\n",
    "outputCols= [f\"{col}_imputed\" for col in inputCols]\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=inputCols,\n",
    "    outputCols=outputCols).setStrategy(\"mean\")\n",
    "\n",
    "df_imputed= imputer.fit(df_pyspark).transform(df_pyspark)\n",
    "df_imputed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
